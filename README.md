# Online Model-Based and Model-Free Reinforcement Learning in Accelerator Operation with Applications to FERMI FEL

##These are the results of RL tests @FERMI-FEL
The problem has four degrees of freedom in state and action space.
A schematic overview:
![SchemaFERMIFEL](Figures/SL_Alignment_Scheme.png)

A new implementation of the NAF with doule Q learning:
![NAF2_training](Figures/FERMI_all_experiments_NAF_episodes.png)

![NAF2_training](Figures/FERMI_all_experiments_NAF_convergence.png)

A new implementation of a AE-dyna:
![AE-DYNA](Figures/AE-DYNA_observables.png)

![AE-DYNA](Figures/AE-DYNA_verification.png)

A variant of the ME-TRPO:
![ME-TRPO](Figures/ME-TRPO_observables.png)

![ME-TRPO](Figures/ME-TRPO_verification.png)

The evolution as presented at GSI [Towards Artificial Intelligence in Accelerator Operation](https://indico.gsi.de/event/11539/):
![ME-TRPO](Figures/Learning_evolution.png)