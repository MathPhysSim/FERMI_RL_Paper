\BOOKMARK [0][-]{section*.2}{Model based reinforcement learning at FERMI FEL}{}% 2
\BOOKMARK [1][-]{section*.1}{Abstract}{section*.2}% 1
\BOOKMARK [1][-]{section*.3}{Introduction and Motivation}{section*.2}% 3
\BOOKMARK [1][-]{section*.4}{The physical set-up}{section*.2}% 4
\BOOKMARK [1][-]{section*.5}{Deep Reinforcement learning}{section*.2}% 5
\BOOKMARK [2][-]{section*.6}{Approximate dynamic programming}{section*.5}% 6
\BOOKMARK [2][-]{section*.7}{NAF}{section*.5}% 7
\BOOKMARK [1][-]{section*.9}{Uncertainty aware Dyna-style reinforcement learning}{section*.2}% 8
\BOOKMARK [2][-]{section*.11}{Critical design decisions}{section*.9}% 9
\BOOKMARK [2][-]{section*.12}{Operational deployment}{section*.9}% 10
\BOOKMARK [2][-]{section*.13}{short FERMI introduction}{section*.9}% 11
\BOOKMARK [2][-]{section*.14}{our system: the modulator and the seed laser}{section*.9}% 12
\BOOKMARK [1][-]{section*.15}{Proof-of-principle application of RL Agent at FERMI trajectory correction}{section*.2}% 13
\BOOKMARK [2][-]{section*.16}{Experiment results from FERMI RL tests}{section*.15}% 14
\BOOKMARK [1][-]{section*.17}{Discussion and outlook}{section*.2}% 15
\BOOKMARK [1][-]{section*.18}{Conclusions}{section*.2}% 16
\BOOKMARK [1][-]{section*.19}{A non-linear standard control problem}{section*.2}% 17
\BOOKMARK [1][-]{section*.20}{NAF2 details}{section*.2}% 18
\BOOKMARK [0][-]{figure.caption.28}{Bibliography}{}% 19
\BOOKMARK [1][-]{section*.29}{References}{figure.caption.28}% 20
